.\" DO NOT MODIFY THIS FILE!  It was generated by help2man 1.47.4.
.TH SPOT-X "7" "September 2019" "spot-x (spot) 2.8.2" "User Commands"
.SH NAME
spot-x \- Common fine-tuning options and environment variables.
.SH SYNOPSIS
.B \-\-extra-options STRING
.br
.B \-x STRING
.SH DESCRIPTION
.\" Add any additional description here
.PP
Common fine\-tuning options for binaries built with Spot.
.PP
The argument of \fB\-x\fR or \fB\-\-extra\-options\fR is a comma\-separated list of KEY=INT
assignments that are passed to the post\-processing routines (they may be passed
to other algorithms in the future). These options are mostly used for
benchmarking and debugging purpose. KEYR (without any value) is a shorthand for
KEY=1, while !KEY is a shorthand for KEY=0.
.SS "Temporal logic simplification options:"
.TP
tls\-impl
Control usage of implication\-based rewriting. (0)
disables it, (1) enables rules based on syntactic
implications, (2) additionally allows
automata\-based implication checks, (3) enables
more rules based on automata\-based implication
checks.  The default value depends on the \fB\-\-low\fR,
\fB\-\-medium\fR, or \fB\-\-high\fR settings.
.SS "Translation options:"
.TP
comp\-susp
Set to 1 to enable compositional suspension, as
described in our SPIN'13 paper (see Bibliography
below).  Set to 2, to build only the skeleton TGBA
without composing it.  Set to 0 (the default) to
disable.
.TP
early\-susp
When set to 1, start compositional suspension on
the transitions that enter accepting SCCs, and not
only on the transitions inside accepting SCCs.
This option defaults to 0, and is only used when
comp\-susp=1.
.TP
ltl\-split
Set to 0 to disable the translation of automata as
product or sum of subformulas.
.TP
skel\-simul
Default to 1.  Set to 0 to disable simulation on
the skeleton automaton during compositional
suspension. Only used when comp\-susp=1.
.TP
skel\-wdba
Set to 0 to disable WDBA minimization on the
skeleton automaton during compositional
suspension. Set to 1 always WDBA\-minimize the
skeleton .  Set to 2 to keep the WDBA only if it
is smaller than the original skeleton.  This
option is only used when comp\-susp=1 and default
to 1 or 2 depending on whether \fB\-\-small\fR or
\fB\-\-deterministic\fR is specified.
.SS "Postprocessing options:"
.TP
ba\-simul
Set to 0 to disable simulation\-based reductions on
automata where state\-based acceptance must be
preserved (e.g., after degeneralization has been
performed).   The name suggests this applies only
to Büchi automata for historical reasons; it
really applies to any state\-based acceptance
nowadays. Set to 1 to use only direct simulation.
Set to 2 to use only reverse simulation.  Set to 3
to iterate both direct and reverse simulations.
The default is 3 in \fB\-\-high\fR mode, and 0 otherwise.
.TP
degen\-lcache
If non\-zero (the default is 1), whenever the
degeneralization algorithm enters an SCC on a
state that has already been associated to a level
elsewhere, it should reuse that level. Different
values can be used to select which level to reuse:
1 always uses the first level created, 2 uses the
minimum level seen so far, and 3 uses the maximum
level seen so far. The "lcache" stands for "level
cache".
.TP
degen\-lowinit
Whenever the degeneralization algorihm enters a
new SCC (or starts from the initial state), it
starts on some level L that is compatible with all
outgoing transitions.  If degen\-lowinit is zero
(the default) and the corresponding state (in the
generalized automaton) has an accepting self\-loop,
then level L is replaced by the accepting level,
as it might favor finding accepting cycles
earlier.  If degen\-lowinit is non\-zero, then level
L is always used without looking for the presence
of an accepting self\-loop.
.TP
degen\-lskip
If non\-zero (the default), the degeneralization
algorithm will skip as much levels as possible for
each transition.  This is enabled by default as it
very often reduce the number of resulting states.
A consequence of skipping levels is that the
degeneralized automaton tends to have smaller
cycles around the accepting states.  Disabling
skipping will produce automata with large cycles,
and often with more states.
.TP
degen\-order
If non\-zero, the degeneralization algorithm will
compute an independent degeneralization order for
each SCC it processes.  This is currently disabled
by default.
.TP
degen\-remscc
If non\-zero (the default), make sure the output of
the degenalization has as many SCCs as the input,
by removing superfluous ones.
.TP
degen\-reset
If non\-zero (the default), the degeneralization
algorithm will reset its level any time it exits
an SCC.
.TP
det\-max\-edges
When defined to a positive integer N,
determinizations will be aborted whenever the
number of generated edges would exceed N.  In this
case a non\-deterministic automaton will be
returned.
.TP
det\-max\-states
When defined to a positive integer N,
determinizations will be aborted whenever the
number of generated states would exceed N.  In
this case a non\-deterministic automaton will be
returned.
.TP
det\-scc
Set to 0 to disable scc\-based optimizations in the
determinization algorithm.
.TP
det\-simul
Set to 0 to disable simulation\-based optimizations
in the determinization algorithm.
.TP
det\-stutter
Set to 0 to disable optimizations based on the
stutter\-invariance in the determinization
algorithm.
.TP
gf\-guarantee
Set to 0 to disable alternate constructions for
GF(guarantee)\->[D]BA and FG(safety)\->DCA.  Those
constructions are from an LICS'18 paper by J.
Esparza, J. Křentínský, and S. Sickert.  This
is enabled by default for medium and high
optimization levels.  Unless we are building
deterministic automata, the resulting automata are
compared to the automata built using the more
traditional pipeline, and only kept if they are
better.
.TP
relabel\-bool
If set to a positive integer N, a formula with N
atomic propositions or more will have its Boolean
subformulas abstracted as atomic propositions
during the translation to automaton. This
relabeling can speeds the translation if a few
Boolean subformulas use a large number of atomic
propositions.  By default N=4.  Setting this value
to 0 will disable the rewriting.
.TP
sat\-acc
When this is set to some positive integer, the
SAT\-based will attempt to construct a TGBA with
the given number of acceptance sets. states.  It
may however return an automaton with less
acceptance sets if some of these are useless.
Setting sat\-acc automatically sets sat\-minimize to
1 if not set differently.
.TP
sat\-incr\-steps
Set the value of sat\-incr\-steps. This variable is
used by two SAT\-based minimization algorithms: (2)
and (3). They are both described below.
.TP
sat\-langmap
Find the lower bound of default sat\-minimize
procedure (1). This relies on the fact that the
size of the minimal automaton is at least equal to
the total number of different languages recognized
by the automaton's states.
.TP
sat\-minimize
Set it to enable SAT\-based minimization of
deterministic TGBA. Depending on its value (from 1
to 4) it changes the algorithm to perform. The
default value is (1) and it proves to be the most
effective method. SAT\-based minimization uses
PicoSAT (distributed with Spot), but another
installed SAT\-solver can be set thanks to the
SPOT_SATSOLVER environment variable. Enabling
SAT\-based minimization will also enable tba\-det.
.TP
sat\-states
When this is set to some positive integer, the
SAT\-based minimization will attempt to construct a
TGBA with the given number of states.  It may
however return an automaton with less states if
some of these are unreachable or useless.  Setting
sat\-states automatically enables sat\-minimize, but
no iteration is performed.  If no equivalent
automaton could be constructed with the given
number of states, the original automaton is
returned.
.TP
scc\-filter
Set to 1 (the default) to enable SCC\-pruning and
acceptance simplification at the beginning of
post\-processing. Transitions that are outside of
accepting SCC are removed from accepting sets,
except those that enter into an accepting SCC. Set
to 2 to remove even these entering transition from
the accepting sets. Set to 0 to disable this
SCC\-pruning and acceptance simpification pass.
.TP
simul
Set to 0 to disable simulation\-based reductions.
Set to 1 to use only direct simulation. Set to 2
to use only reverse simulation. Set to 3 to
iterate both direct and reverse simulations. The
default is 3, except when option \fB\-\-low\fR is
specified, in which case the default is 1.
.TP
state\-based
Set to 1 to instruct the SAT\-minimization
procedure to produce a TGBA where all outgoing
transition of a state have the same acceptance
sets.  By default this is only enabled when option
\fB\-B\fR is used.
.TP
tba\-det
Set to 1 to attempt a powerset determinization if
the TGBA is not already deterministic.  Doing so
will degeneralize the automaton.  This is disabled
by default, unless sat\-minimize is set.
.TP
wdba\-minimize
Set to 0 to disable WDBA\-minimization.  Enabled by
default.
.SH "SAT\-MINIMIZE VALUES"
.TP
\fB1\fR
Used by default, \fB1\fR performs a binary search, checking N/2, etc.
The upper bound being N (the size of the starting automaton), the lower bound
is always 1 except when \fBsat-langmap\fR option is used.

.TP
\fB2\fR
Use PicoSAT assumptions. Each iteration encodes the search of an (N\-1) state
equivalent automaton, and additionally assumes that the last
\fBsat\-incr\-steps\fR states are unnecessary. On failure, relax the assumptions
to do a binary search between N\-1 and N\-1\-\fBsat\-incr\-steps\fR.
\fBsat\-incr\-steps\fR defaults to 6.

.TP
\fB3\fR
After an (N\-1) state automaton has been found, use incremental solving for
the next \fBsat\-incr\-steps\fR iterations by forbidding the usage of an
additional state without reencoding the problem again. A full encoding will
occur after \fBsat\-incr\-steps\fR iterations unless \fBsat\-incr\-steps=-1\fR
(see \fBSPOT_XCNF\fR environment variable). \fBsat\-incr\-steps\fR defaults to
2.

.TP
\fB4\fR
This naive method tries to reduce the size of the automaton one state at a
time. Note that it restarts all the encoding each time.
.SH "ENVIRONMENT VARIABLES"
.TP
\fBSPOT_BDD_TRACE\fR
If this variable is set to any value, statistics about BDD garbage
collection and resizing will be output on standard error.

.TP
\fBSPOT_DEFAULT_FORMAT\fR
Set to a value of \fBdot\fR or \fBhoa\fR to override the default
format used to output automata.  Up to Spot 1.9.6 the default output
format for automata used to be \fBdot\fR.  Starting with Spot 1.9.7,
the default output format switched to \fBhoa\fR as it is more
convenient when chaining tools in a pipe.  Set this variable to
\fBdot\fR to get the old behavior.  Additional options may be
passed to the printer by suffixing the output format with
\fB=\fR and the options.  For instance running
.in +4n
.EX
% SPOT_DEFAULT_FORMAT=dot=bar autfilt ...
.EN
.in -4n
is the same as running
.in +4n
.EX
% autfilt --dot=bar ...
.EE
.in -4n
but the use of the environment variable makes more sense if you set
it up once for many commands.

.TP
\fBSPOT_DEBUG_PARSER\fR
If this variable is set to any value, the automaton parser of Spot is
executed in debug mode, showing how the input is processed.

.TP
\fBSPOT_DOTDEFAULT\fR
Whenever the \f(CW--dot\fR option is used without argument (even
implicitely via \fBSPOT_DEFAULT_FORMAT\fR), the contents of this
variable is used as default argument.  If you have some default
settings in \fBSPOT_DOTDEFAULT\fR and want to append to options
\f(CWxyz\fR temporarily for one call, use \f(CW--dot=.xyz\fR:
the dot character will be replaced by the contents of the
\f(CWSPOT_DOTDEFAULT\fR environment variable.

.TP
\fBSPOT_DOTEXTRA\fR
The contents of this variable is added to any dot output, immediately
before the first state is output.  This makes it easy to override
global attributes of the graph.

.TP
\fBSPOT_HOA_TOLERANT\fR
If this variable is set, a few sanity checks performed by the HOA
parser are skipped.  The tests in questions correspond to issues
in third-party tools that output incorrect HOA (e.g., declaring
the automaton with property "univ-branch" when no universal branching
is actually used)

.TP
\fBSPOT_O_CHECK\fR
Specifies the default algorithm that should be used
by the \f(CWis_obligation()\fR function.  The value should
be one of the following:
.RS
.RS
.IP 1
Make sure that the formula and its negation are
realizable by non-deterministic co-Büchi automata.
.IP 2
Make sure that the formula and its negation are
realizable by deterministic Büchi automata.
.IP 3
Make sure that the formula is realizable
by a weak and deterministic Büchi automata.
.RE
.RE

.TP
\fBSPOT_OOM_ABORT\fR
If this variable is set, Out-Of-Memory errors will \f(CWabort()\fR the
program (potentially generating a coredump) instead of raising an
exception.  This is useful to debug a program and to obtain a stack
trace pointing to the function doing the allocation.  When this
variable is unset (the default), \f(CWstd::bad_alloc\fR are thrown on
memory allocation failures, and the stack is usually unwinded up to
top-level, losing the original context of the error.  Note that at
least \f(CWltlcross\fR has some custom handling of
\f(CWstd::bad_alloc\fR to recover from products that are too large (by
ignoring them), and setting this variable will interfer with that.

.TP
\fBSPOT_PR_CHECK\fR
Select the default algorithm that must be used to check the persistence
or recurrence property of a formula f. The values it can take are between
1 and 3. All  methods work either on f or !f thanks to the duality of
persistence and recurrence classes.  See
.UR https://spot.lrde.epita.fr/hierarchy.html
this page
.UE
for more details. If it is set to:
.RS
.RS
.IP 1
It will try to check if f (or !f) is co-Büchi realizable in order to
tell if f belongs to the persistence (or the recurrence) class.
.IP 2
It checks if f (or !f) is det-Büchi realizable via a reduction
to deterministic-Rabin in order to tell if f belongs to the
recurrence (or the persistance) class.
.IP 3
It checks if f (or !f) is det-Büchi realizable via a reduction
to deterministic-parity in order to tell if f belongs to the
recurrence (or the persistance) class.
.RE
.RE

.TP
\fBSPOT_SATLOG\fR
If set to a filename, the SAT-based minimization routines will append
statistics about each iteration to the named file.  Each line lists
the following comma-separated values: input number of states, target
number of states, number of reachable states in the output, number of
edges in the output, number of transitions in the output, number of
variables in the SAT problem, number of clauses in the SAT problem,
user time for encoding the SAT problem, system time for encoding the
SAT problem, user time for solving the SAT problem, system time for
solving the SAT problem, automaton produced at this step in HOA
format.

.TP
\fBSPOT_SATSOLVER\fR
If set, this variable should indicate how to call an external
SAT\-solver \- by default, Spot uses PicoSAT, which is distributed
with. This is used by the sat\-minimize option described above.
The format to follow is the following: \f(CW"<sat_solver> [options] %I >%O"\fR.
The escape sequences \f(CW%I\fR and \f(CW%O\fR respectively
denote the names of the input and output files.  These temporary files
are created in the directory specified by \fBSPOT_TMPDIR\fR or
\fBTMPDIR\fR (see below). The SAT\-solver should follow the convention
of the SAT Competition for its input and output format.

.TP
\fBSPOT_STREETT_CONV_MIN\fR
The number of Streett pairs above which conversion from Streett
acceptance to generalized-Büchi acceptance should be made with a
dedicated algorithm.  By default this is 3, i.e., if a Streett
automaton with 3 acceptance pairs or more has to be converted into
generalized-Büchi, the dedicated algorithm is used.  This algorithm is
close to the classical conversion from Streett to Büchi, but with
several tweaks.  When this algorithm is not used, the standard
"Fin-removal" approach is used instead: first the acceptance condition
is converted into disjunctive normal form (DNF), then Fin acceptance
is removed like for Rabin automata, yielding a disjuction of
generalized Büchi acceptance, and the result is finally converted into
conjunctive normal form (CNF) to obtain a generalized Büchi
acceptance.  Both algorithms have a worst-case size that is
exponential in the number of Streett pairs, but in practice the
dedicated algorithm works better for most Streett automata with 3 or
more pairs (and many 2-pair Streett automata as well, but the
difference here is less clear).  Setting this variable to 0 will
disable the dedicated algorithm.  Setting it to 1 will enable it for
all Streett automata, however we do not recommand setting it to less
than 2, because the "Fin-removal" approach is better for single-pair
Streett automata.

.TP
\fBSPOT_STUTTER_CHECK\fR
Select the default check used to decide stutter invariance.  The
variable should hold a value between 1 and 8, corresponding to the
following tests described in our Spin'15 paper (see the BIBLIOGRAPHY
section).  The default is 8.
.RS
.RS
.IP 1
sl(a) x sl(!a)
.IP 2
sl(cl(a)) x !a
.IP 3
cl(sl(a)) x !a
.IP 4
sl2(a) x sl2(!a)
.IP 5
sl2(cl(a)) x !a
.IP 6
cl(sl2(a)) x !a
.IP 7
sl(a) x sl(!a), performed on-the-fly
.IP 8
cl(a) x cl(!a)
.RE
.RE

.TP
\fBSPOT_TMPDIR\fR, \fBTMPDIR\fR
These variables control in which directory temporary files (e.g.,
those who contain the input and output when interfacing with
translators) are created.  \fBTMPDIR\fR is only read if
\fBSPOT_TMPDIR\fR does not exist.  If none of these environment
variables exist, or if their value is empty, files are created in the
current directory.

.TP
\fBSPOT_TMPKEEP\fR
When this variable is defined, temporary files are not removed.
This is mostly useful for debugging.

.TP
\fBSPOT_XCNF\fR
Assign a folder path to this variable to generate XCNF files whenever
SAT\-based minimization is used \- the file is outputed as "incr.xcnf"
in the specified directory. This feature works only with an external
SAT\-solver. See \fBSPOT_SATSOLVER\fR to know how to provide one. Also note
that this needs an incremental approach without restarting the encoding i.e
"sat\-minimize=3,param=-1" for ltl2tgba and ltl2tgta or "incr,param=-1" for
autfilt (see sat\-minimize options described above or autfilt man page).
The XCNF format is the one used by the SAT incremental competition.
.SH BIBLIOGRAPHY
.TP
1.
Christian Dax, Jochen Eisinger, Felix Klaedtke: Mechanizing the
Powerset Construction for Restricted Classes of
ω-Automata. Proceedings of ATVA'07.  LNCS 4762.

Describes the WDBA-minimization algorithm implemented in Spot.  The
algorithm used for the tba-det options is also a generalization (to
TBA instead of BA) of what they describe in sections 3.2 and 3.3.

.TP
2.
Tomáš Babiak, Thomas Badie, Alexandre Duret-Lutz, Mojmír Křetínský,
Jan Strejček: Compositional Approach to Suspension and Other
Improvements to LTL Translation.  Proceedings of SPIN'13.  LNCS 7976.

Describes the compositional suspension, the simulation-based
reductions, and the SCC-based simplifications.

.TP
3.
Rüdiger Ehlers: Minimising Deterministic Büchi Automata Precisely using
SAT Solving.  Proceedings of SAT'10.  LNCS 6175.

Our SAT-based minimization procedures are generalizations of this
paper to deal with TBA or TGBA.

.TP
4.
Thibaud Michaud and Alexandre Duret-Lutz: Practical stutter-invariance
checks for ω-regular languages, Proceedings of SPIN'15.  LNCS 9232.

Describes the stutter-invariance checks that can be selected through
\fBSPOT_STUTTER_CHECK\fR.

.TP
5.
Javier Esparza, Jan Křetínský and Salomon Sickert: One Theorem to Rule
Them All: A Unified Translation of LTL into ω-Automata.  Proceedings
of LICS'18.  To appear.

Describes (among other things) the constructions used for translating
formulas of the form GF(guarantee) or FG(safety), that can be
disabled with \fB-x gf-guarantee=0\fR.
.SH "REPORTING BUGS"
Report bugs to <spot@lrde.epita.fr>.
.SH COPYRIGHT
Copyright \(co 2019  Laboratoire de Recherche et Développement de l'Epita.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>.
.br
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
.SH "SEE ALSO"
.BR ltl2tgba (1)
.BR ltl2tgta (1)
.BR dstar2tgba (1)
.BR autfilt (1)
